# Models_regression
https://colab.research.google.com/drive/18MEDA7DXsWujfzs7bg9vJAaKrRPMqHHo

## О проекте
Анализ данных с помощью различных моделей машинного обучения.  
Тип задачи - классификация (два класса - 0 и 1).  
Цель - определение модели, показывающей самую высокую точность предсказания.  
Исходные данные сгенерированы с помощью функции "make_classification". Разделение классов - нечеткое, чтобы продемонстрировать преимущества "сложных" моделей прогнозирования с большим количеством настраиваемых параметров.    


## Используемые технологии
- Google Colab / Jupyter Notebook
- Python
- Pandas
- Numpy
- Matplotlib
- Scikit-learn  


## Таблица метрических показателей моделей
|         Model         |     MAE     |     MAPE    |     RMSE    |     R^2     |
|:---------------------:|:-----------:|:-----------:|:-----------:|:-----------:|
|   Linear Regression   |  39945.805  |    0.254    |  49830.818  |    0.572    |
|      CatBoost         |  39976.572  |    0.255    |  49872.091  |    0.572    |
|      CatBoost (2)     |  39962.327  |    0.255    |  49874.036  |    0.571    |
|    Random Forest      |  40048.973  |    0.255    |  50021.188  |    0.569    |
|         SVR           |  40828.241  |    0.271    |  51083.247  |    0.55     |
|         MLP           |  39956.223  |    0.25     |  49863.444  |    0.572    |


CatBoost (2) - CatBoost (on normalized data and transformed categorical data).  


## Выбор модели

Самые точные результаты выдает модель MLP, далее CatBoost, ненамного отстает SVM. Здесь все довольно предсказуемо. Выигрывают те модели, которые позволяют делать настройку с помощью большого количества параметров. И самые лучшие результаты показывает Многослойный перцептрон (MLP), основанный на нейронных сетях, что довольно предсказуемо. НО!, чтобы добиться высокой точности результатов, необходимо подбирать значения параметров. Большую помощь в этом оказывает случайный (рандомизированный) поиск - RandomizedSearchCV().

Самая неточная модель - Naive Bayes, чуть поточнее Logistic Regression. Что немного удивительно. В большинстве случаев, самые грубые результаты показывают линейные модели (в данной задаче Logistic Regression). Скорее всего, Наивный Байес совершенно не подходит для данной задачи или параметры выбраны неверно.   


==============================

> Автором проекта является Middle Data Scientist
> 
> Запесочный Владислав
> 
> Страница на github: https://github.com/SpeZzz0R  
> 
